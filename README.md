项目简介
本项目围绕中文文本欺诈检测任务，基于预训练语言模型 BERT，设计并实现了一组文本改写对抗实验与消融实验，用于分析模型在不同改写策略下的鲁棒性表现。
实验重点关注在未进行下游任务微调的前提下，模型面对语义保持改写（同义词替换、整句级改写）时的性能变化情况。

实验环境
Python ≥ 3.8
PyTorch
Transformers (HuggingFace)
pandas
scikit-learn
matplotlib

预训练模型：
hfl/chinese-bert-wwm-ext

项目结构说明
project/
│
├── data/
│   ├── test.csv              # 原始测试集
│   ├── test_adv.csv          # 改写攻击测试集
│   ├── test_synonym.csv      # 同义词替换测试集
│   └── test_sentence.csv     # 整句级改写测试集
│
├── result/
│   └── figure1.png            # 不同测试集准确率对比图
│
├── baseline.py                # 原始测试集与改写测试集评估
├── ablation_test.py           # 消融实验主程序（含可视化）
├── rewrite_attack.py          # 改写攻击数据生成脚本
├── rewrite_synonym.py         # 同义词替换数据生成脚本
├── rewrite_sentence.py        # 整句级改写数据生成脚本
└── README.md

各脚本功能说明
1. baseline.py
使用预训练 BERT 模型
在原始测试集与改写攻击测试集上评估分类准确率
作为基础性能对照

2. rewrite_attack.py
对原始测试集进行语义保持改写
生成 test_adv.csv
用于测试模型在改写攻击下的整体鲁棒性

3. rewrite_synonym.py
仅进行词汇级同义词替换
保持句法结构基本不变
生成 test_synonym.csv
用于消融实验中的“同义词替换”策略评估

4. rewrite_sentence.py
对文本进行整句级语义改写
改变句法结构和表达方式，但保持原有语义
生成 test_sentence.csv
用于消融实验中的“整句改写”策略评估

5. ablation_test.py
统一评估以下四个测试集：
原始测试集
改写攻击测试集
同义词替换测试集
整句改写测试集
输出各测试集的分类准确率
自动生成并保存准确率对比柱状图

实验结果示例
在当前实验设置下，模型在不同测试集上的准确率如下：
测试集类型	准确率
原始测试集	0.482
改写攻击测试集	0.600
同义词替换	0.485
整句改写	0.483

实验结果表明，在未进行下游任务微调的情况下，模型在面对语义保持改写时未出现明显性能退化，不同改写粒度对预测结果的影响较小。

主要结论
语义保持的文本改写（同义词替换、整句改写）在当前实验条件下未显著削弱模型性能
模型对不同改写策略表现出的稳定性，更多源于其整体判别能力有限
改写操作在一定程度上起到了文本规范化作用，甚至在部分情况下提升了预测一致性
后续工作可在经过充分下游任务微调的模型上，进一步评估改写对抗的有效性

说明
本项目为课程实验用途，重点在于实验设计、现象分析与结论讨论，而非追求模型最优性能。
